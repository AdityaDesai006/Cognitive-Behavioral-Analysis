{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the code for extracting cnn features from facial features using cnn<br>\n",
        "1: Truth<br>\n",
        "0: Lie <br> <br>"
      ],
      "metadata": {
        "id": "kk12PvZJEL2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SEQ_LEN = 20\n",
        "SEED_VAL = 0\n",
        "\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128"
      ],
      "metadata": {
        "id": "fwDZG_pDEm6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing libraries"
      ],
      "metadata": {
        "id": "gz8uR4_iEdfN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e39BORIBEAlz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.layers import *\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.applications import ResNet50V2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading dataset"
      ],
      "metadata": {
        "id": "DqWsZXmmEiOF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FACIAL_FEATURES_PATH = \"/content/drive/MyDrive/CDAC-Project(Personal)/numpy-arrays/Videos/Version 3/video-frame-facial-features(20).npz\"\n",
        "LABELS_PATH = \"/content/drive/MyDrive/CDAC-Project(Personal)/numpy-arrays/Videos/Version 3/video-frame-labels(20).npz\""
      ],
      "metadata": {
        "id": "jrTIuJhsEjjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = np.load(FACIAL_FEATURES_PATH)[\"arr_0\"]\n",
        "labels = np.load(LABELS_PATH)[\"arr_0\"]"
      ],
      "metadata": {
        "id": "nzjiK-4MRN3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "KwWCDjCRRcj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lengths:\\nfacial features: {}, labels: {}\".format(len(features), len(labels)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Hwdx9pBRW0c",
        "outputId": "00d65333-d9d5-43ed-c9e1-92e844ae4680"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lengths:\n",
            "facial features: 325, labels: 325\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shapes:\\nfacial features: {}, labels: {}\".format(features.shape, labels.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76tir4RBRmWF",
        "outputId": "3949c1a1-fc68-4a24-bc93-c804d2236c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "facial features: (325, 20, 128, 128, 3), labels: (325,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Test Split"
      ],
      "metadata": {
        "id": "jqgJQbRgSVa5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "features_train, features_test, labels_train, labels_test = train_test_split(features, labels, test_size=0.25, random_state=SEED_VAL)"
      ],
      "metadata": {
        "id": "UYlWQZ37R7jP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shapes\\nTrain:\\nFeatures: {}, labels: {}\\n\\nTest:\\nFeatures:{}, labels: {}\".format(\n",
        "    features_train.shape, labels_train.shape, features_test.shape, labels_test.shape\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWFyh6W4SqVe",
        "outputId": "b774719d-51a6-467f-b184-88d92bc15f8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes\n",
            "Train:\n",
            "Features: (243, 20, 128, 128, 3), labels: (243,)\n",
            "\n",
            "Test:\n",
            "Features:(82, 20, 128, 128, 3), labels: (82,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Value counts"
      ],
      "metadata": {
        "id": "zLYuDmvtSmrd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train\\n{}\\n\\nTest\\n{}\".format(pd.value_counts(labels_train), pd.value_counts(labels_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDxCgGoNSkg0",
        "outputId": "8477a542-1196-453d-adc8-1e7d781d3bf6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "1    125\n",
            "0    118\n",
            "dtype: int64\n",
            "\n",
            "Test\n",
            "0    44\n",
            "1    38\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN Model"
      ],
      "metadata": {
        "id": "I1TluQFESvh1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Callbacks"
      ],
      "metadata": {
        "id": "Pgx4MN21Sy70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVED_MODEL_PATH = \"/content/drive/MyDrive/CDAC-Project(Personal)/saved-models/video/Version 3/video-CNN({})\".format(SEQ_LEN)\n",
        "\n",
        "cnn_cbk1 = tf.keras.callbacks.ModelCheckpoint(filepath=SAVED_MODEL_PATH,\n",
        "                                             save_weights_only=False,\n",
        "                                             monitor=\"val_accuracy\",\n",
        "                                             mode=\"max\",\n",
        "                                             verbose=1,\n",
        "                                             save_best_only=True)\n",
        "\n",
        "\n",
        "cnn_cbk2 = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                            patience=25,\n",
        "                                            verbose=1,\n",
        "                                            mode=\"min\")"
      ],
      "metadata": {
        "id": "n8RVErU7Sxhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Model"
      ],
      "metadata": {
        "id": "HB9olKl9TcIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn_model() :\n",
        "    conv_base = ResNet50V2(weights=\"imagenet\",\n",
        "                           include_top=False,\n",
        "                           input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "    inp = Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
        "\n",
        "    x = conv_base(inp)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Dropout(0.20)(x)\n",
        "\n",
        "    x = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
        "\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    op = Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "\n",
        "    model = Model(inp, op)\n",
        "    opt = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "dwdH9lBLTdoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model = create_cnn_model()"
      ],
      "metadata": {
        "id": "dExT3wu5TxUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypMagCo_TxwN",
        "outputId": "f6ae6bbb-578c-43a1-b411-7935f3f7e795"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 4, 4, 2048)        23564800  \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 2048)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 2048)        0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 2, 2, 512)         9437696   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 1, 1, 256)         1179904   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,182,657\n",
            "Trainable params: 34,137,217\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "AZgWU9UeT_bN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_reshaped_features(features, labels, num_frames=SEQ_LEN) :\n",
        "    \"\"\"\n",
        "    returns reshaped features and labels for cnn model (separates sequential frames into new rows)\n",
        "    \"\"\"\n",
        "\n",
        "    # Duplicating label values for each frames\n",
        "\n",
        "    cnn_labels = list()\n",
        "\n",
        "    for i in range(features.shape[0]) :\n",
        "        for j in range(num_frames) :\n",
        "            cnn_labels.append(labels[i])\n",
        "\n",
        "    cnn_labels = np.array(cnn_labels)\n",
        "\n",
        "    # Changing label into 1D\n",
        "    reshaped_cnn_labels = np.reshape(cnn_labels, (-1, 1))\n",
        "\n",
        "    # Reshaping features\n",
        "    dim1 = features.shape[0] * features.shape[1]\n",
        "    dim2 = features.shape[2]\n",
        "    dim3 = features.shape[3]\n",
        "    dim4 = features.shape[4]\n",
        "\n",
        "    reshaped_cnn_features = np.reshape(features, (dim1, dim2, dim3, dim4))\n",
        "\n",
        "    return reshaped_cnn_features, reshaped_cnn_labels"
      ],
      "metadata": {
        "id": "_gIlpYX0UA3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_features_train, cnn_labels_train = get_reshaped_features(features_train, labels_train)"
      ],
      "metadata": {
        "id": "cN_msORtUGPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cnn_features_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zLL2obURUG7G",
        "outputId": "b4f534d4-ddc1-412e-a909-9b8fc8c0a929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4860, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cnn_labels_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Nwv5mq_UIcJ",
        "outputId": "95e1e7cf-30d3-4f83-aab3-c4297d438cc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4860, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = cnn_model.fit(cnn_features_train, cnn_labels_train, epochs=200, validation_split=0.10, shuffle=True, callbacks=[cnn_cbk1, cnn_cbk2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_n2P3AGUKeN",
        "outputId": "7a8bc831-ce62-4a8d-ba60-04b35ba2b7f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.7557 - accuracy: 0.5482\n",
            "Epoch 1: val_accuracy improved from -inf to 0.52058, saving model to /content/drive/MyDrive/CDAC-Project(Personal)/saved-models/video/Version 3/video-CNN(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r137/137 [==============================] - 57s 345ms/step - loss: 0.7557 - accuracy: 0.5482 - val_loss: 0.9804 - val_accuracy: 0.5206\n",
            "Epoch 2/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6783 - accuracy: 0.5565\n",
            "Epoch 2: val_accuracy did not improve from 0.52058\n",
            "137/137 [==============================] - 18s 133ms/step - loss: 0.6783 - accuracy: 0.5565 - val_loss: 1.5868 - val_accuracy: 0.4815\n",
            "Epoch 3/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6827 - accuracy: 0.5592\n",
            "Epoch 3: val_accuracy improved from 0.52058 to 0.53086, saving model to /content/drive/MyDrive/CDAC-Project(Personal)/saved-models/video/Version 3/video-CNN(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r137/137 [==============================] - 47s 347ms/step - loss: 0.6827 - accuracy: 0.5592 - val_loss: 0.6897 - val_accuracy: 0.5309\n",
            "Epoch 4/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6909 - accuracy: 0.5290\n",
            "Epoch 4: val_accuracy did not improve from 0.53086\n",
            "137/137 [==============================] - 19s 141ms/step - loss: 0.6909 - accuracy: 0.5290 - val_loss: 1.7104 - val_accuracy: 0.4218\n",
            "Epoch 5/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6776 - accuracy: 0.5793\n",
            "Epoch 5: val_accuracy improved from 0.53086 to 0.54938, saving model to /content/drive/MyDrive/CDAC-Project(Personal)/saved-models/video/Version 3/video-CNN(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r137/137 [==============================] - 43s 317ms/step - loss: 0.6776 - accuracy: 0.5793 - val_loss: 0.6900 - val_accuracy: 0.5494\n",
            "Epoch 6/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6860 - accuracy: 0.5299\n",
            "Epoch 6: val_accuracy did not improve from 0.54938\n",
            "137/137 [==============================] - 18s 132ms/step - loss: 0.6860 - accuracy: 0.5299 - val_loss: 0.9902 - val_accuracy: 0.4671\n",
            "Epoch 7/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6795 - accuracy: 0.5473\n",
            "Epoch 7: val_accuracy improved from 0.54938 to 0.55761, saving model to /content/drive/MyDrive/CDAC-Project(Personal)/saved-models/video/Version 3/video-CNN(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r137/137 [==============================] - 46s 334ms/step - loss: 0.6795 - accuracy: 0.5473 - val_loss: 0.7008 - val_accuracy: 0.5576\n",
            "Epoch 8/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6757 - accuracy: 0.5722\n",
            "Epoch 8: val_accuracy improved from 0.55761 to 0.57202, saving model to /content/drive/MyDrive/CDAC-Project(Personal)/saved-models/video/Version 3/video-CNN(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r137/137 [==============================] - 43s 318ms/step - loss: 0.6757 - accuracy: 0.5722 - val_loss: 0.7789 - val_accuracy: 0.5720\n",
            "Epoch 9/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6681 - accuracy: 0.5629\n",
            "Epoch 9: val_accuracy did not improve from 0.57202\n",
            "137/137 [==============================] - 19s 135ms/step - loss: 0.6681 - accuracy: 0.5629 - val_loss: 1.1884 - val_accuracy: 0.4588\n",
            "Epoch 10/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6697 - accuracy: 0.5679\n",
            "Epoch 10: val_accuracy improved from 0.57202 to 0.60905, saving model to /content/drive/MyDrive/CDAC-Project(Personal)/saved-models/video/Version 3/video-CNN(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r137/137 [==============================] - 52s 378ms/step - loss: 0.6697 - accuracy: 0.5679 - val_loss: 0.6627 - val_accuracy: 0.6091\n",
            "Epoch 11/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6781 - accuracy: 0.5510\n",
            "Epoch 11: val_accuracy did not improve from 0.60905\n",
            "137/137 [==============================] - 19s 135ms/step - loss: 0.6781 - accuracy: 0.5510 - val_loss: 0.6826 - val_accuracy: 0.5885\n",
            "Epoch 12/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6833 - accuracy: 0.5412\n",
            "Epoch 12: val_accuracy improved from 0.60905 to 0.63169, saving model to /content/drive/MyDrive/CDAC-Project(Personal)/saved-models/video/Version 3/video-CNN(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r137/137 [==============================] - 44s 319ms/step - loss: 0.6833 - accuracy: 0.5412 - val_loss: 0.6778 - val_accuracy: 0.6317\n",
            "Epoch 13/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6778 - accuracy: 0.5505\n",
            "Epoch 13: val_accuracy did not improve from 0.63169\n",
            "137/137 [==============================] - 19s 135ms/step - loss: 0.6778 - accuracy: 0.5505 - val_loss: 0.6892 - val_accuracy: 0.5473\n",
            "Epoch 14/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6729 - accuracy: 0.5594\n",
            "Epoch 14: val_accuracy did not improve from 0.63169\n",
            "137/137 [==============================] - 18s 133ms/step - loss: 0.6729 - accuracy: 0.5594 - val_loss: 0.6947 - val_accuracy: 0.5556\n",
            "Epoch 15/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6627 - accuracy: 0.5750\n",
            "Epoch 15: val_accuracy did not improve from 0.63169\n",
            "137/137 [==============================] - 19s 136ms/step - loss: 0.6627 - accuracy: 0.5750 - val_loss: 0.6547 - val_accuracy: 0.6152\n",
            "Epoch 16/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6882 - accuracy: 0.5473\n",
            "Epoch 16: val_accuracy did not improve from 0.63169\n",
            "137/137 [==============================] - 19s 135ms/step - loss: 0.6882 - accuracy: 0.5473 - val_loss: 0.6833 - val_accuracy: 0.5885\n",
            "Epoch 17/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.5332\n",
            "Epoch 17: val_accuracy did not improve from 0.63169\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6888 - accuracy: 0.5332 - val_loss: 0.9268 - val_accuracy: 0.6296\n",
            "Epoch 18/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6978 - accuracy: 0.5240\n",
            "Epoch 18: val_accuracy did not improve from 0.63169\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6978 - accuracy: 0.5240 - val_loss: 0.6861 - val_accuracy: 0.5885\n",
            "Epoch 19/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6812 - accuracy: 0.5421\n",
            "Epoch 19: val_accuracy improved from 0.63169 to 0.64198, saving model to /content/drive/MyDrive/CDAC-Project(Personal)/saved-models/video/Version 3/video-CNN(20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 55). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r137/137 [==============================] - 42s 308ms/step - loss: 0.6812 - accuracy: 0.5421 - val_loss: 1.7531 - val_accuracy: 0.6420\n",
            "Epoch 20/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6819 - accuracy: 0.5535\n",
            "Epoch 20: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 132ms/step - loss: 0.6819 - accuracy: 0.5535 - val_loss: 0.6811 - val_accuracy: 0.5967\n",
            "Epoch 21/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6741 - accuracy: 0.5686\n",
            "Epoch 21: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 133ms/step - loss: 0.6741 - accuracy: 0.5686 - val_loss: 0.7483 - val_accuracy: 0.5473\n",
            "Epoch 22/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6696 - accuracy: 0.5736\n",
            "Epoch 22: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 19s 135ms/step - loss: 0.6696 - accuracy: 0.5736 - val_loss: 0.7194 - val_accuracy: 0.5535\n",
            "Epoch 23/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6627 - accuracy: 0.5759\n",
            "Epoch 23: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 19s 140ms/step - loss: 0.6627 - accuracy: 0.5759 - val_loss: 0.7890 - val_accuracy: 0.5967\n",
            "Epoch 24/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6643 - accuracy: 0.5700\n",
            "Epoch 24: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 130ms/step - loss: 0.6643 - accuracy: 0.5700 - val_loss: 0.7041 - val_accuracy: 0.5658\n",
            "Epoch 25/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6651 - accuracy: 0.5647\n",
            "Epoch 25: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 130ms/step - loss: 0.6651 - accuracy: 0.5647 - val_loss: 0.7263 - val_accuracy: 0.5885\n",
            "Epoch 26/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6590 - accuracy: 0.5693\n",
            "Epoch 26: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6590 - accuracy: 0.5693 - val_loss: 0.6972 - val_accuracy: 0.5905\n",
            "Epoch 27/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6586 - accuracy: 0.5780\n",
            "Epoch 27: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6586 - accuracy: 0.5780 - val_loss: 0.7271 - val_accuracy: 0.5412\n",
            "Epoch 28/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6585 - accuracy: 0.5800\n",
            "Epoch 28: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 132ms/step - loss: 0.6585 - accuracy: 0.5800 - val_loss: 0.6626 - val_accuracy: 0.6296\n",
            "Epoch 29/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6588 - accuracy: 0.5878\n",
            "Epoch 29: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 132ms/step - loss: 0.6588 - accuracy: 0.5878 - val_loss: 0.7010 - val_accuracy: 0.5885\n",
            "Epoch 30/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6507 - accuracy: 0.5944\n",
            "Epoch 30: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6507 - accuracy: 0.5944 - val_loss: 1.2476 - val_accuracy: 0.5720\n",
            "Epoch 31/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.5908\n",
            "Epoch 31: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6538 - accuracy: 0.5908 - val_loss: 0.8737 - val_accuracy: 0.5926\n",
            "Epoch 32/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6452 - accuracy: 0.5985\n",
            "Epoch 32: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6452 - accuracy: 0.5985 - val_loss: 1.1867 - val_accuracy: 0.5782\n",
            "Epoch 33/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6497 - accuracy: 0.5947\n",
            "Epoch 33: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6497 - accuracy: 0.5947 - val_loss: 1.2032 - val_accuracy: 0.5761\n",
            "Epoch 34/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6399 - accuracy: 0.6017\n",
            "Epoch 34: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6399 - accuracy: 0.6017 - val_loss: 1.5117 - val_accuracy: 0.5658\n",
            "Epoch 35/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6381 - accuracy: 0.6054\n",
            "Epoch 35: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 132ms/step - loss: 0.6381 - accuracy: 0.6054 - val_loss: 1.8554 - val_accuracy: 0.5700\n",
            "Epoch 36/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6413 - accuracy: 0.5969\n",
            "Epoch 36: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 133ms/step - loss: 0.6413 - accuracy: 0.5969 - val_loss: 1.1335 - val_accuracy: 0.5844\n",
            "Epoch 37/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6357 - accuracy: 0.6063\n",
            "Epoch 37: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6357 - accuracy: 0.6063 - val_loss: 1.5532 - val_accuracy: 0.5638\n",
            "Epoch 38/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6355 - accuracy: 0.6006\n",
            "Epoch 38: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6355 - accuracy: 0.6006 - val_loss: 0.7913 - val_accuracy: 0.5761\n",
            "Epoch 39/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6321 - accuracy: 0.6061\n",
            "Epoch 39: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6321 - accuracy: 0.6061 - val_loss: 2.4294 - val_accuracy: 0.5658\n",
            "Epoch 40/200\n",
            "137/137 [==============================] - ETA: 0s - loss: 0.6343 - accuracy: 0.6056\n",
            "Epoch 40: val_accuracy did not improve from 0.64198\n",
            "137/137 [==============================] - 18s 131ms/step - loss: 0.6343 - accuracy: 0.6056 - val_loss: 1.4468 - val_accuracy: 0.5658\n",
            "Epoch 40: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Saving CNN extracted features"
      ],
      "metadata": {
        "id": "DZ4RJ4OvZ7WW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CNN_OP_SIZE = 256"
      ],
      "metadata": {
        "id": "sgN8b3-JbTsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_reshaped, labels_reshaped = get_reshaped_features(features, labels)"
      ],
      "metadata": {
        "id": "DSKeI20RZaBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(features_reshaped.shape, labels_reshaped.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leM1w6wPdlsG",
        "outputId": "8d412297-fac8-4a9e-9da0-671f8e8fa30a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6500, 128, 128, 3) (6500, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model(SAVED_MODEL_PATH)"
      ],
      "metadata": {
        "id": "6mpWkXZhaJ5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APjD5OzsaWtt",
        "outputId": "637f139e-000d-4e1a-adf9-77967c152325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 128, 128, 3)]     0         \n",
            "                                                                 \n",
            " resnet50v2 (Functional)     (None, 4, 4, 2048)        23564800  \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 2, 2, 2048)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2, 2, 2048)        0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 2, 2, 512)         9437696   \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 1, 1, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 1, 1, 256)         1179904   \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 256)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34,182,657\n",
            "Trainable params: 34,137,217\n",
            "Non-trainable params: 45,440\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_outputs = model.get_layer(\"conv2d_1\").output\n",
        "child_model = tf.keras.models.Model(inputs=model.inputs, outputs=model_outputs)"
      ],
      "metadata": {
        "id": "_dYQPODXabSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model_output = child_model.predict(features_reshaped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJ9HwiqQanPD",
        "outputId": "efe6eca3-b907-4deb-cc02-e2ab9f4ff201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "204/204 [==============================] - 8s 35ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUzwedn_apY1",
        "outputId": "05ec60a1-ffa6-4857-e702-627209584462"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6500, 1, 1, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dim1 = features.shape[0]\n",
        "dim2 = features.shape[1]\n",
        "dim3 = CNN_OP_SIZE"
      ],
      "metadata": {
        "id": "W4S0lsveazLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model_output = gen_model_output.reshape((dim1, dim2, dim3))"
      ],
      "metadata": {
        "id": "-p7yg3F1b49D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model_output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqHdSJewb92D",
        "outputId": "d696ba80-988c-4516-b9a4-dfcfae8b58a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(325, 20, 256)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_SAVE_PATH = \"/content/drive/MyDrive/CDAC-Project(Personal)/numpy-arrays/Videos/Version 3/video-cnn-features({}).npz\".format(SEQ_LEN)\n",
        "np.savez_compressed(OUTPUT_SAVE_PATH, gen_model_output)"
      ],
      "metadata": {
        "id": "qpUyMZCMcbqc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}